# DataLake_Sample_Project_1


ğŸ› ï¸ Data Lake Project - Titanic Dataset

This project demonstrates the implementation of a multi-layered data lake architecture using Python, applied to a modified Titanic dataset. It includes data ingestion, transformation, and analytics, showcasing the core principles of data engineering.

ğŸ“ Project Structure
--------------------
Data-Lake-Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample.json           - Sample JSON file (may contain CSV data)
â”‚   â””â”€â”€ sample.csv            - Sample CSV file
â”œâ”€â”€ data_lake/
â”‚   â”œâ”€â”€ raw/                  - Raw layer: Initial ingested data
â”‚   â”œâ”€â”€ refined/              - Refined layer: Cleaned data
â”‚   â”œâ”€â”€ curated/              - Curated layer: Standardized data
â”‚   â”œâ”€â”€ enriched/             - Enriched layer: Enhanced data with new features
â”‚   â””â”€â”€ transformed/          - Transformed layer: Aggregated and summarized data
â”œâ”€â”€ visualizations/           - Directory for generated charts (currently empty)
â”œâ”€â”€ main.py                   - Main pipeline script for data processing
â”œâ”€â”€ analytics_visualization.py - Script for analytics and visualization (to be implemented)
â””â”€â”€ README.md                 - Project documentation



You can view the structured directory here 
![{6B8D2F44-4438-47C6-BDD7-D735A234A5FE}](https://github.com/user-attachments/assets/206be39c-427b-4593-bf77-d910fe45f2c8)


ğŸŒŠ Data Lake Layers
--------------------
Each layer of the data lake stores progressively processed versions of the dataset:

- Raw: Original unprocessed data.
- Refined: Cleaned data with basic formatting.
- Curated: Structured data with selected features.
- Enriched: Additional derived metrics or columns.
- Transformed: Final output ready for analytics and reporting.

ğŸ”„ Data Pipeline
--------------------
The pipeline performs the following tasks:
1. Loads raw JSON data.
2. Processes and saves each stage to its corresponding layer.
3. Converts final output to CSV format for analysis.

ğŸ“Š Analytics and Visualization
--------------------
The analytics_visualization.py script performs insights and visualization on the transformed data.

Visualizations Include:
- Survival Rate by Passenger Class
- Average Fare by Class
- Survival Rate by Embarkation Port
- Correlation Heatmap between Fare and Survival Rate

All charts are saved in:  
data_lake/visualizations/

ğŸ“¦ Requirements
--------------------
Install the required Python packages:

pip install pandas matplotlib seaborn

â–¶ï¸ How to Run
--------------------
1. Run the Data Pipeline:
   python main.py

2. Generate Analytics and Charts:
   python analytics_visualization.py

ğŸ§  Insights
--------------------
The transformed dataset shows survival patterns across different passenger classes and ports of embarkation, with meaningful correlations between fare and survival rates. The project mirrors real-world ETL + analytics pipelines used in data engineering.

ğŸ Final Notes
--------------------
This project is part of my learning journey to become a Data Engineer.  
Feel free to fork, adapt, or contribute ideas!

ğŸ™‹â€â™‚ï¸ Author
--------------------
Lokesh Kumar
LinkedIn: https://www.linkedin.com/in/lokesh-kumar-ab41a819a/
